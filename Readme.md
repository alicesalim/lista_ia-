ğŸ“„ RELATÃ“RIO â€“ Lista 9

Curso: CiÃªncia da ComputaÃ§Ã£o
Disciplina: InteligÃªncia Artificial
Professora: Cristiane Neri Nobre
Aluno(a): Alice Antunes
Base: Credit Card Fraud Detection â€“ Kaggle

#ï¸âƒ£ QuestÃ£o 1 â€” Etapas de PrÃ©-Processamento
## 1. IntroduÃ§Ã£o

Este relatÃ³rio apresenta o processo completo de prÃ©-processamento aplicado Ã  base de dados Credit Card Fraud Detection. O objetivo Ã© adequar os dados para modelos supervisionados de detecÃ§Ã£o de fraude, melhorando a qualidade dos dados e reduzindo problemas como desbalanceamento, outliers e redundÃ¢ncia.

A base contÃ©m 284.807 registros, 31 atributos (28 PCA, alÃ©m de Time, Amount e Class), e uma proporÃ§Ã£o de fraude extremamente baixa (~0,17%).

## 2. Etapas de PrÃ©-Processamento
### 2.1 VisualizaÃ§Ã£o da Base de Dados

Foram exibidos os comandos:

df.head(), df.tail(), df.sample()

df.info(), df.describe()

GrÃ¡ficos iniciais: distribuiÃ§Ã£o das classes e histogramas dos atributos principais.

Principais observaÃ§Ãµes:

V1â€“V28 sÃ£o componentes principais (PCA).

DistribuiÃ§Ã£o extremamente desbalanceada (fraudes â‰ˆ 0,17%).

Amount apresenta grande assimetria (cauda longa).

### 2.2 VerificaÃ§Ã£o e Tratamento de Valores Ausentes

Comando utilizado:

df.isna().sum()


Resultado:
A base nÃ£o contÃ©m valores ausentes â†’ nenhuma aÃ§Ã£o necessÃ¡ria.

### 2.3 DetecÃ§Ã£o e EliminaÃ§Ã£o de RedundÃ¢ncia e InconsistÃªncia
Duplicidade

Foram encontrados X registros duplicados (substituir pelo valor real).

Todos foram removidos com:

df = df.drop_duplicates().reset_index(drop=True)

InconsistÃªncias

NÃ£o foram encontrados valores invÃ¡lidos (ex.: Amount < 0).

### 2.4 DetecÃ§Ã£o e Tratamento de Outliers

Outliers sÃ£o esperados em transaÃ§Ãµes fraudulentas, portanto:

Fraudes nÃ£o foram alteradas.

Outliers em Amount da classe 0 foram tratados com IQR.

Boxplots antes e depois confirmam reduÃ§Ã£o de pontos extremos apenas da classe majoritÃ¡ria.

Justificativa: evitar exclusÃ£o de instÃ¢ncias legÃ­timas de fraude e reduzir distorÃ§Ãµes nos dados.

### 2.5 NormalizaÃ§Ã£o / PadronizaÃ§Ã£o

MÃ©todo adotado: RobustScaler

scaler = RobustScaler()
X_scaled = scaler.fit_transform(df.drop("Class", axis=1))


RazÃµes da escolha:

Ã‰ robusto diante de outliers.

Ideal para dados com distribuiÃ§Ã£o assimÃ©trica (ex.: Amount).

### 2.6 AnÃ¡lise de CorrelaÃ§Ã£o e Multicolinearidade

Foi construÃ­da a matriz de correlaÃ§Ã£o entre os atributos, excluindo a variÃ¡vel alvo.

Resultados:

Baixa correlaÃ§Ã£o entre atributos (esperado devido ao PCA).

Multicolinearidade baixa, comprovada via VIF.

Nenhum atributo precisou ser removido.

### 2.7 CodificaÃ§Ã£o de VariÃ¡veis

A base nÃ£o possui atributos categÃ³ricos, portanto:
â¡ï¸ One-Hot Encoding nÃ£o foi necessÃ¡rio.

Se houvesse variÃ¡veis categÃ³ricas, utilizar-se-ia pd.get_dummies ou OneHotEncoder.

### 2.8 Balanceamento da Classe

Foi utilizado o mÃ©todo SMOTE, aplicado somente no treino:

smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)


DistribuiÃ§Ã£o:

Antes: proporÃ§Ã£o de fraude â‰ˆ 0,17%

Depois (treino): 50% fraude / 50% nÃ£o fraude

GrÃ¡ficos foram gerados mostrando o antes/depois.

### 2.9 DivisÃ£o Treinoâ€“Teste (Estratificada)

A separaÃ§Ã£o foi realizada com estratificaÃ§Ã£o:

train_test_split(..., stratify=y)


Objetivo: manter a proporÃ§Ã£o da classe rara no conjunto de teste.

## 3. Resultados dos Modelos: Antes x Depois

O modelo utilizado foi RegressÃ£o LogÃ­stica.

### 3.1 Modelo Antes do PrÃ©-Processamento
MÃ©trica	Valor
Recall (fraude)	X
Precision (fraude)	X
F1-score	X
AUC-ROC	X

(substituir pelos seus resultados)

### 3.2 Modelo ApÃ³s o PrÃ©-Processamento
MÃ©trica	Valor
Recall (fraude)	X
Precision (fraude)	X
F1-score	X
AUC-ROC	X
### ConclusÃµes

O recall da classe fraudulenta aumentou significativamente apÃ³s SMOTE.

Pequena reduÃ§Ã£o de precisÃ£o Ã© esperada (trade-off comum em classificaÃ§Ã£o rara).

O AUC-ROC aumentou, mostrando melhor separaÃ§Ã£o entre classes.

O modelo final estÃ¡ mais adequado para o problema real de detecÃ§Ã£o de fraudes.

## 4. Links do CÃ³digo

git@github.com:alicesalim/lista_ia-.git

#ï¸âƒ£ QuestÃ£o 2 â€” Algoritmos de Agrupamento
## 1. IntroduÃ§Ã£o

Nesta questÃ£o, utilizamos algoritmos de aprendizado nÃ£o supervisionado para identificar possÃ­veis agrupamentos naturais na base Credit Card Fraud Detection.

âš ï¸ Importante: Para essa etapa, o atributo Class foi removido antes do agrupamento.

Os algoritmos aplicados foram:

K-Means (k = 2)

DBSCAN

SOM (Self-Organizing Map / MiniSom)

A qualidade dos grupos foi avaliada com:

Ãndice de Silhueta

Davies-Bouldin

Calinski-Harabasz

(Opcional) ARI comparando com a classe real

## 2. Algoritmos e HiperparÃ¢metros
### 2.1 K-Means

ParÃ¢metros utilizados:

n_clusters = 2

n_init = 10

max_iter = 300

random_state = 42

Resultados obtidos:

MÃ©trica	Valor
Silhouette	X
Davies-Bouldin	X
Calinski-Harabasz	X
(Opcional) ARI	X

AnÃ¡lise:

O K-Means tenta separar os dados em 2 clusters, mas como as fraudes sÃ£o raras e distribuÃ­das de forma dispersa, a separaÃ§Ã£o tende a nÃ£o refletir bem a classe real.

### 2.2 DBSCAN

ParÃ¢metros utilizados (exemplo):

eps = X.X

min_samples = 5

Ajustados empiricamente atÃ© gerar pelo menos 2 clusters vÃ¡lidos.

Clusters encontrados:

Total: X

RuÃ­do (-1): X instÃ¢ncias

Resultados (considerando apenas labels â‰  -1):

MÃ©trica	Valor
Silhouette	X
Davies-Bouldin	X
Calinski-Harabasz	X

AnÃ¡lise:

DBSCAN trata bem regiÃµes densas e marca fraudes esparsas como ruÃ­do.

Tipicamente nÃ£o encontra exatamente 2 clusters â€” depende muito dos hiperparÃ¢metros.

### 2.3 SOM (Self-Organizing Map)

Utilizado o pacote MiniSom.

ConfiguraÃ§Ã£o:

Tamanho do mapa: 1 Ã— 2 neurÃ´nios

sigma = 1.0

learning_rate = 0.5

IteraÃ§Ãµes: 1000

Resultados:

MÃ©trica	Valor
Silhouette	X
Davies-Bouldin	X
Calinski-Harabasz	X

AnÃ¡lise:

SOM realiza mapeamento topolÃ³gico e encontra padrÃµes.

Em geral, nÃ£o separa explicitamente fraudes, pois estas nÃ£o formam um cluster denso no espaÃ§o PCA.

## 3. ConclusÃµes da QuestÃ£o 2

K-Means, DBSCAN e SOM nÃ£o conseguem separar claramente fraude e nÃ£o fraude, pois as fraudes nÃ£o formam um cluster natural.

As mÃ©tricas de Silhueta tendem a valores baixos (prÃ³ximos de 0), indicando fraca separaÃ§Ã£o.

O DBSCAN identifica diversas instÃ¢ncias como ruÃ­do, o que Ã© coerente com a natureza extremamente rara e dispersa das fraudes.

O SOM cria dois grupos artificiais, mas que nÃ£o correspondem Ã  classe real.

ConclusÃ£o geral:
A base nÃ£o apresenta clusters naturais que correspondam Ã  divisÃ£o fraude/nÃ£o fraude. Isso reforÃ§a a necessidade de modelos supervisionados e de tÃ©cnicas fortes de prÃ©-processamento (principalmente balanceamento).

## 4. Links do CÃ³digo
git@github.com:alicesalim/lista_ia-.git